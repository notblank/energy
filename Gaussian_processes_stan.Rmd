---
title: "gaussian processes"
author: "FZ"
date: "3/18/2021"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(tidyverse)
library(rstan)
library(rstanarm)
library(bayesplot)
```

## GP over 5 points:

```{stan, output.var="gp1"}

data {
  int<lower=1> N;
  real x[N];
}

transformed data {
  matrix[N, N] K;
  vector[N] mu = rep_vector(0, N);
  for (i in 1:(N - 1)) {
    K[i, i] = 1 + 0.1;
    for (j in (i + 1):N) {
      K[i, j] = exp(-0.5 * square(x[i] - x[j]));
      K[j, i] = K[i, j];
    }
  }
  K[N, N] = 1 + 0.1;
}
parameters {
  vector[N] y;
}
model {
  y ~ multi_normal(mu, K);
}
  
```


## Fitting the model:


```{r}

gp_data <- list(N = 10, x = seq(1, 10))
gp_data

fit = sampling(object = gp1, data = gp_data)

```

### Posterior Samples from a GP:

```{r}

posterior <- extract(fit, inc_warmup = FALSE)

n_samples <- dim(posterior$y)[1]

as.tibble(posterior$y) %>%
  mutate(sample_n = 1:n_samples) %>%
  pivot_longer(cols = -sample_n, names_to = "vars", values_to = "mcmc_samples") %>%
  filter(sample_n <= 10) %>%
  mutate(x = rep(1:10, 10), sample_n = factor(sample_n)) %>%
  ggplot(aes(x, mcmc_samples, color = sample_n)) +
  geom_line() +
  labs(title = "10 samples from a GP") +
  theme(legend.position = "none")


```

## Fitting a GP:

1- Estimate the params | data.
2- Plug-in the params and predict.

```{stan, output.var="gp_params"}

data {
  int<lower=1> N;
  real x[N];
  vector[N] y;
}

transformed data {
  vector[N] mu = rep_vector(0, N);
}

parameters {
  real<lower=0> rho;
  real<lower=0> alpha;
  real<lower=0> sigma;
}

model {
  matrix[N, N] L_K;
  matrix[N, N] K = cov_exp_quad(x, alpha, rho);
  real sq_sigma = square(sigma);

  // diagonal elements
  for (n in 1:N)
    K[n, n] = K[n, n] + sq_sigma;

  L_K = cholesky_decompose(K);

  rho ~ inv_gamma(5, 5);
  alpha ~ std_normal();
  sigma ~ std_normal();

  y ~ multi_normal_cholesky(mu, L_K);
}

```


## Estimating the parameters:


```{r}

N <- 30
x <- seq(0, 2, length.out = N)
y <- sin(x) + rnorm(N, 0, 1)

gp_params_data <- list(N = N, x = x, y = y)
gp_params_data

fit_params = sampling(object = gp_params, data = gp_params_data)

```

```{r}

fit_params

```

```{r}

param_posteriors <- extract(fit_params, inc_warmup = TRUE, permuted = FALSE)

color_scheme_set("mix-blue-pink")
p <- mcmc_trace(param_posteriors,  pars = c("rho", "alpha", "sigma"), n_warmup = 300,
                facet_args = list(nrow = 2, labeller = label_parsed))
p + facet_text(size = 15)
```

```{r}

mcmc_areas(fit_params, regex_pars = c("rho", "alpha", "sigma"),  prob = 0.8) +
 labs(
   title = "Posterior distributions",
   subtitle = "with medians and 80% intervals"
 )

```

#### Posterior distribution:


```{r}

posterior_summary <-
  as.tibble(extract(fit_params)) %>%
  select(-lp__) %>%
  pivot_longer(cols = c("rho", "alpha", "sigma"), 
               names_to = "param", values_to = "mcmc_estimate") %>%
  group_by(param) %>%
  summarise(mean_p = mean(mcmc_estimate), sd_p = sd(mcmc_estimate))

fit_params

```

## Predictive model:

- add generated quantities at the end.

- most of the post pred density is computed using functions.

```{stan, output.var="gp_pred"}

functions {

  matrix KxX_IKXX(int N1, int N2, real[] x1, real[] x2, real alpha, real rho){
  
    matrix[N2, N2] Kx2x2 = cov_exp_quad(x2, alpha, rho);
    
    matrix[N1, N2] Kx1x2;
    
    for(r in 1:N1){
      for(c in 1:N2){
        Kx1x2[r, c] = 
          square(alpha) * exp(- square(x1[r] - x2[c]) / (2 * square(rho)));
      }
    }
    return Kx1x2 * inverse(Kx2x2);
  }
}

data {
  int<lower=1> N;
  real x[N];
  vector[N] y;
  // pred:
  int<lower=1> N_new;
  real x_new[N_new];
}

transformed data {
  vector[N] mu = rep_vector(0, N);
}

parameters {
  real<lower=0> rho;
  real<lower=0> alpha;
  real<lower=0> sigma;
}

model {
  matrix[N, N] L_K;
  matrix[N, N] K = cov_exp_quad(x, alpha, rho);
  real sq_sigma = square(sigma);

  // diagonal elements
  for (n in 1:N)
    K[n, n] = K[n, n] + sq_sigma;

  L_K = cholesky_decompose(K);

  rho ~ inv_gamma(5, 5);
  alpha ~ std_normal();
  sigma ~ std_normal();

  y ~ multi_normal_cholesky(mu, L_K);
}

generated quantities {

  vector[N_new] y_new;
  y_new = KxX_IKXX(N_new, N, x_new, x, alpha, rho) * y;
  
}

```

```{r}

N <- 10
x <- seq(0, 2, length.out = N)
y <- sin(x) + runif(N, 0, 0.1)

N_new <- 2
x_new <- c(0.23, 1.23)

gp_pred_data <- list(N = N, x = x, y = y, 
                     N_new = N_new, x_new = x_new)
gp_pred_data

fit_pred <- sampling(gp_pred, data = gp_pred_data)

```

```{r}

fit_pred

```

